{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wave\n",
    "import openai\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "openai.api_key = 'API_KEY'\n",
    "\n",
    "# 오디오 녹음 함수\n",
    "def record_audio(filename='presentation.wav', duration=60, fs=44100):\n",
    "    print(\"녹음을 시작합니다...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=2, dtype='int16')\n",
    "    sd.wait()  # 녹음이 끝날 때까지 대기\n",
    "    print(\"녹음이 완료되었습니다.\")\n",
    "    \n",
    "    # WAV 파일로 저장\n",
    "    with wave.open(filename, 'w') as wf:\n",
    "        wf.setnchannels(2)\n",
    "        wf.setsampwidth(2)  # 16-bit\n",
    "        wf.setframerate(fs)\n",
    "        wf.writeframes(recording.tobytes())\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# Whisper를 사용하여 오디오 파일을 텍스트로 변환\n",
    "def transcribe_audio(file_path):\n",
    "    with open(file_path, \"rb\") as audio_file:\n",
    "        response = openai.Audio.transcribe(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file\n",
    "        )\n",
    "    return response['text']\n",
    "\n",
    "# PDF에서 텍스트 추출\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# 텍스트 비교 및 피드백 제공\n",
    "def generate_feedback(pdf_text, presentation_text):\n",
    "    prompt = f\"\"\"\n",
    "    아래는 논문 PDF에서 추출한 텍스트와 발표자의 음성 파일을 텍스트로 변환한 내용입니다. 두 텍스트를 비교하여, 문맥의 일관성, 주요 주제의 정확성, 그리고 발표의 명확성에 대해 피드백을 제공해 주세요. 또한, 발표자가 개선할 수 있는 부분에 대한 제언도 포함해 주세요. 모든 피드백은 한국어로 작성해 주세요.\n",
    "\n",
    "    논문 PDF 텍스트:\n",
    "    {pdf_text}\n",
    "\n",
    "    발표 텍스트:\n",
    "    {presentation_text}\n",
    "\n",
    "    피드백:\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        n=1,\n",
    "        stop=None\n",
    "    )\n",
    "    return response.choices[0].text\n",
    "\n",
    "# 텍스트 비교 및 예상 질문 생성\n",
    "def generate_comparison_questions(pdf_text, presentation_text):\n",
    "    prompt = f\"\"\"\n",
    "    아래는 논문 PDF에서 추출한 텍스트와 발표자의 음성 파일을 텍스트로 변환한 내용입니다. 두 텍스트를 비교하여, 발표 내용을 기반으로 예상 질문을 5개 작성해 주세요. 모든 질문은 한국어로 작성해 주세요.\n",
    "\n",
    "    논문 PDF 텍스트:\n",
    "    {pdf_text}\n",
    "\n",
    "    발표 텍스트:\n",
    "    {presentation_text}\n",
    "\n",
    "    예상 질문:\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        n=1,\n",
    "        stop=None\n",
    "    )\n",
    "    return response.choices[0].text\n",
    "\n",
    "# 메인 인터랙션 함수\n",
    "def chat_bot():\n",
    "    # 1. 녹음을 시작한다.\n",
    "    # duration = int(input(\"녹음 시간을 입력하세요 (초): \"))\n",
    "    check_audio = input(\"녹음을 시작하시겠습니까? (예/아니오): \").strip().lower()\n",
    "    if check_audio == '예':\n",
    "        audio_file = record_audio(duration=120)\n",
    "\n",
    "    else:\n",
    "        print(\"대화를 종료합니다.\")\n",
    "        # 끝내기\n",
    "        return   \n",
    "\n",
    "    # 2. 녹음이 끝나면 pdf 를 제출할 것이냐는 물음을 한다.\n",
    "    submit_pdf = input(\"PDF를 제출하시겠습니까? (예/아니오): \").strip().lower()\n",
    "\n",
    "    if submit_pdf == '예' or submit_pdf == '제출':\n",
    "        pdf_path = \"./research.pdf\"\n",
    "        # 3. pdf 파일을 받아왔다면 \"pdf 제출 완료\" 라는 말과 함께 \"1. 피드백 받기  2. 예상 질문 받기\" 를 선택하도록 묻는다.\n",
    "        print(\"PDF 제출 완료\")\n",
    "        \n",
    "        action = input(\"원하는 작업을 선택하세요: 1. 피드백 받기  2. 예상 질문 받기: \").strip()\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "        presentation_text = transcribe_audio(audio_file)\n",
    "        \n",
    "        if action == '1' or action == '피드백' or action == '1. 피드백 받기' or action == '피드백 받기':\n",
    "            feedback = generate_feedback(pdf_text, presentation_text)\n",
    "            print(\"피드백: \\n\", feedback)\n",
    "        elif action == '2' or action == '예상 질문' or action == '2. 예상 질문 받기' or action == '예상 질문 받기':\n",
    "            questions = generate_comparison_questions(pdf_text, presentation_text)\n",
    "            print(\"예상 질문: \\n\", questions)\n",
    "        else:\n",
    "            print(\"잘못된 입력입니다. 대화를 종료합니다.\")\n",
    "            return\n",
    "        \n",
    "        # 6. 또 다른 질문이 있는지 물어본다.\n",
    "        another_question = input(\"또 다른 질문이 있으신가요? (예/아니오): \").strip().lower()\n",
    "        if another_question == '예':\n",
    "            chat_bot()  # 재귀 호출로 다시 시작\n",
    "        else:\n",
    "            print(\"대화를 종료합니다.\")\n",
    "    else:\n",
    "        # 7. 없다하면 대화 종료\n",
    "        print(\"대화를 종료합니다.\")\n",
    "\n",
    "# 챗봇 실행\n",
    "chat_bot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
