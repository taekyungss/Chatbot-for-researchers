{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"]='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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7870\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-> Paper id 2306.04938v1 with title 'Knowledge Detection by Relevant Question and Image Attributes in Visual Question Answering' is downloaded as 2306.04938v1.Knowledge_Detection_by_Relevant_Question_and_Image_Attributes_in_Visual_Question_Answering.pdf.\n",
            "-> Paper id 2308.11662v2 with title 'VQA Therapy: Exploring Answer Differences by Visually Grounding Answers' is downloaded as 2308.11662v2.VQA_Therapy:_Exploring_Answer_Differences_by_Visually_Grounding_Answers.pdf.\n",
            "-> Paper id 2304.01647v1 with title 'SC-ML: Self-supervised Counterfactual Metric Learning for Debiased Visual Question Answering' is downloaded as 2304.01647v1.SC-ML:_Self-supervised_Counterfactual_Metric_Learning_for_Debiased_Visual_Question_Answering.pdf.\n",
            "-> Paper id 2306.06622v2 with title 'Weakly Supervised Visual Question Answer Generation' is downloaded as 2306.06622v2.Weakly_Supervised_Visual_Question_Answer_Generation.pdf.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import gradio as gr\n",
        "import openai\n",
        "import fitz  # PyMuPDF\n",
        "import os\n",
        "import arxiv\n",
        "import time\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain import hub\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "\n",
        "# Module 1: 발표 검사\n",
        "def transcribe_audio(file_path):\n",
        "    audio_file = open(file_path, \"rb\")\n",
        "    response = openai.Audio.transcribe(\"whisper-1\", file=audio_file)\n",
        "    return response['text']\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    document = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(document)):\n",
        "        page = document.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "def generate_feedback_or_questions(pdf_text, presentation_text, task):\n",
        "    if '피드백' in task or 'feedback' in task:\n",
        "        prompt = f\"\"\"\n",
        "        아래는 논문 PDF에서 추출한 텍스트와 발표자의 음성 파일을 텍스트로 변환한 내용입니다. 두 텍스트를 비교하여, 문맥의 일관성, 주요 주제의 정확성, 그리고 발표의 명확성에 대해 피드백을 제공해 주세요. 또한, 발표자가 개선할 수 있는 부분에 대한 제언도 포함해 주세요. 모든 피드백은 한국어로 작성해 주세요.\n",
        "\n",
        "        논문 PDF 텍스트:\n",
        "        {pdf_text}\n",
        "\n",
        "        발표 텍스트:\n",
        "        {presentation_text}\n",
        "\n",
        "        피드백:\n",
        "        \"\"\"\n",
        "    elif '질문' in task or 'question' in task:\n",
        "        prompt = f\"\"\"\n",
        "        아래는 논문 PDF에서 추출한 텍스트와 발표자의 음성 파일을 텍스트로 변환한 내용입니다. 두 텍스트를 비교하여, 발표 내용을 기반으로 예상 질문을 5개 작성해 주세요. 모든 질문은 한국어로 작성해 주세요.\n",
        "\n",
        "        논문 PDF 텍스트:\n",
        "        {pdf_text}\n",
        "\n",
        "        발표 텍스트:\n",
        "        {presentation_text}\n",
        "\n",
        "        예상 질문:\n",
        "        \"\"\"\n",
        "    else:\n",
        "        return \"적절한 작업을 선택하지 않았습니다. '피드백' 또는 '질문'을 포함하는 작업을 입력하세요.\"\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=1000,\n",
        "        temperature=0.7,\n",
        "        n=1,\n",
        "        stop=None\n",
        "    )\n",
        "    return response.choices[0].text\n",
        "\n",
        "state = {\"audio_path\": None, \"pdf_path\": None, \"pdf_text\": None, \"presentation_text\": None, \"task\": None, \"saved_files\": []}\n",
        "\n",
        "def upload_files(audio, pdf):\n",
        "    try:\n",
        "        state[\"audio_path\"] = audio\n",
        "        state[\"pdf_path\"] = pdf\n",
        "        state[\"pdf_text\"] = extract_text_from_pdf(pdf)\n",
        "        state[\"presentation_text\"] = transcribe_audio(audio)\n",
        "        return \"파일 업로드가 완료되었습니다. 피드백을 원하시면 '피드백', 예상 질문을 원하시면 '질문'이라고 입력하세요.\"\n",
        "    except Exception as e:\n",
        "        return f\"파일 업로드 중 오류가 발생했습니다: {e}\"\n",
        "\n",
        "def set_task(task):\n",
        "    state[\"task\"] = task\n",
        "    return handle_task(task)\n",
        "\n",
        "def handle_task(task):\n",
        "    if state[\"audio_path\"] and state[\"pdf_path\"] and state[\"pdf_text\"] and state[\"presentation_text\"]:\n",
        "        result = generate_feedback_or_questions(state[\"pdf_text\"], state[\"presentation_text\"], task)\n",
        "        return result\n",
        "    else:\n",
        "        return \"먼저 오디오 파일과 PDF 파일을 업로드해 주세요.\"\n",
        "\n",
        "# Module 2: 논문 검색\n",
        "def download_papers_between_years(query, start_year, end_year, num_papers=10):\n",
        "    dirpath = \"./arxiv_papers\"\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)\n",
        "    \n",
        "    search_query = f\"{query} AND submittedDate:[{start_year}-01-01 TO {end_year}-12-31]\"\n",
        "    \n",
        "    client = arxiv.Client()\n",
        "    search = arxiv.Search(\n",
        "        query=search_query,\n",
        "        max_results=num_papers,\n",
        "        sort_order=arxiv.SortOrder.Descending\n",
        "    )\n",
        "    \n",
        "    saved_files = []\n",
        "    \n",
        "    for result in client.results(search):\n",
        "        while True:\n",
        "            try:\n",
        "                title = result.title.replace(' ', '_')\n",
        "                filename = f\"{result.get_short_id()}.{title}.pdf\"\n",
        "                result.download_pdf(dirpath=dirpath, filename=filename)\n",
        "                saved_files.append(filename)\n",
        "                print(f\"-> Paper id {result.get_short_id()} with title '{result.title}' is downloaded as {filename}.\")\n",
        "                break\n",
        "            except (FileNotFoundError, ConnectionResetError) as e:\n",
        "                print(\"Error occurred:\", e)\n",
        "                time.sleep(5)\n",
        "    \n",
        "    state[\"saved_files\"] = saved_files\n",
        "    return saved_files\n",
        "\n",
        "def open_pdf(file_name):\n",
        "    dirpath = \"./arxiv_papers\"\n",
        "    file_path = os.path.join(dirpath, file_name)\n",
        "    os.system(f'start {file_path}')\n",
        "\n",
        "def query_rag_model(file_name, question):\n",
        "    dirpath = \"./arxiv_papers\"\n",
        "    file_path = os.path.join(dirpath, file_name)\n",
        "\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=docs, \n",
        "        embedding=OpenAIEmbeddings()\n",
        "    )\n",
        "\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0.7)\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
        "        | rag_prompt \n",
        "        | llm \n",
        "    )\n",
        "\n",
        "    response = rag_chain.invoke(question)\n",
        "    return response.content\n",
        "\n",
        "def download_interface(query, start_year, end_year, num_papers):\n",
        "    saved_files = download_papers_between_years(query, start_year, end_year, num_papers)\n",
        "    return gr.update(choices=saved_files), \"논문이 다운로드 되었습니다.\"\n",
        "\n",
        "def open_pdf_and_chat_interface(selected_file, question):\n",
        "    if selected_file and not question:\n",
        "        open_pdf(selected_file)\n",
        "        return f\"{selected_file} 파일을 열고 있습니다...\", \"\"\n",
        "    elif selected_file and question:\n",
        "        response = query_rag_model(selected_file, question)\n",
        "        result = ''.join(filter(None, response))\n",
        "        return \"\", result\n",
        "    else:\n",
        "        return \"파일을 선택하고 질문을 입력하세요.\", \"\"\n",
        "\n",
        "def reset_interface():\n",
        "    state[\"saved_files\"] = []\n",
        "    return gr.update(visible=False), gr.update(visible=False), \"\", \"안녕하세요, 연구자를 위한 챗봇 리서처입니다. 발표 검사와 논문 검색 중 어느 모듈을 사용하실래요?\", gr.update(choices=[])\n",
        "\n",
        "# Combined Interface\n",
        "with gr.Blocks() as iface:\n",
        "    with gr.Row():\n",
        "        gr.Markdown(\"## 연구자를 위한 챗봇 리서처\")\n",
        "\n",
        "    with gr.Row():\n",
        "        chatbox = gr.Textbox(label=\"챗봇\", placeholder=\"발표 검사 또는 논문 검색을 입력하세요\")\n",
        "        chat_button = gr.Button(\"전송\")\n",
        "    \n",
        "    output_text = gr.Textbox(label=\"출력\")\n",
        "\n",
        "    with gr.Row(visible=False) as module_1:\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 발표 피드백 및 질문 생성기\")\n",
        "            audio_input = gr.Audio(type=\"filepath\", label=\"발표 녹음\")\n",
        "            pdf_input = gr.File(label=\"PDF 파일 업로드\")\n",
        "            upload_button = gr.Button(\"파일 업로드\")\n",
        "            upload_button.click(upload_files, inputs=[audio_input, pdf_input], outputs=output_text)\n",
        "            task_input = gr.Textbox(label=\"작업 입력\", placeholder=\"피드백 또는 질문\")\n",
        "            task_button = gr.Button(\"작업 전송\")\n",
        "            task_button.click(set_task, inputs=task_input, outputs=output_text)\n",
        "\n",
        "    with gr.Row(visible=False) as module_2:\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 논문 검색 및 챗봇\")\n",
        "            query_input = gr.Textbox(label=\"검색 쿼리 입력\")\n",
        "            start_year_input = gr.Number(label=\"시작 연도\")\n",
        "            end_year_input = gr.Number(label=\"종료 연도\")\n",
        "            num_papers_input = gr.Number(label=\"논문 수\")\n",
        "            download_button = gr.Button(\"논문 다운로드\")\n",
        "            saved_files_dropdown = gr.Dropdown(label=\"저장된 논문 선택\", choices=[])\n",
        "            download_button.click(download_interface, inputs=[query_input, start_year_input, end_year_input, num_papers_input], outputs=[saved_files_dropdown, output_text])\n",
        "\n",
        "            question_input = gr.Textbox(label=\"질문 입력\", placeholder=\"예: vqa의 방법론을 알려줘\")\n",
        "            query_button = gr.Button(\"질문 전송\")\n",
        "            query_button.click(open_pdf_and_chat_interface, inputs=[saved_files_dropdown, question_input], outputs=[output_text, output_text])\n",
        "\n",
        "    reset_button = gr.Button(\"초기화\")\n",
        "\n",
        "    def chatbot_response(input_text):\n",
        "        if \"발표 검사\" in input_text:\n",
        "            return \"발표 검사 모듈을 선택하셨습니다. 파일을 업로드하고 작업을 입력하세요.\", gr.update(visible=True), gr.update(visible=False)\n",
        "        elif \"논문 검색\" in input_text:\n",
        "            return \"논문 검색 모듈을 선택하셨습니다. 검색 쿼리와 조건을 입력하세요.\", gr.update(visible=False), gr.update(visible=True)\n",
        "        else:\n",
        "            return \"유효한 명령을 입력하세요: 발표 검사 또는 논문 검색.\", gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    chat_button.click(chatbot_response, inputs=chatbox, outputs=[output_text, module_1, module_2])\n",
        "    reset_button.click(reset_interface, inputs=[], outputs=[module_1, module_2, chatbox, output_text, saved_files_dropdown])\n",
        "\n",
        "iface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7873\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import gradio as gr\n",
        "import openai\n",
        "import fitz  # PyMuPDF\n",
        "import os\n",
        "import arxiv\n",
        "import time\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain import hub\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "\n",
        "# Module 1: 발표 검사\n",
        "def transcribe_audio(file_path):\n",
        "    audio_file = open(file_path, \"rb\")\n",
        "    response = openai.Audio.transcribe(\"whisper-1\", file=audio_file)\n",
        "    return response['text']\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    document = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(document)):\n",
        "        page = document.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "def generate_feedback_or_questions(pdf_text, presentation_text, task):\n",
        "    if '피드백' in task or 'feedback' in task:\n",
        "        prompt = f\"\"\"\n",
        "        아래는 논문 PDF에서 추출한 텍스트와 발표자의 음성 파일을 텍스트로 변환한 내용입니다. 두 텍스트를 비교하여, 문맥의 일관성, 주요 주제의 정확성, 그리고 발표의 명확성에 대해 피드백을 제공해 주세요. 또한, 발표자가 개선할 수 있는 부분에 대한 제언도 포함해 주세요. 모든 피드백은 한국어로 작성해 주세요.\n",
        "\n",
        "        논문 PDF 텍스트:\n",
        "        {pdf_text}\n",
        "\n",
        "        발표 텍스트:\n",
        "        {presentation_text}\n",
        "\n",
        "        피드백:\n",
        "        \"\"\"\n",
        "    elif '질문' in task or 'question' in task:\n",
        "        prompt = f\"\"\"\n",
        "        아래는 논문 PDF에서 추출한 텍스트와 발표자의 음성 파일을 텍스트로 변환한 내용입니다. 두 텍스트를 비교하여, 발표 내용을 기반으로 예상 질문을 5개 작성해 주세요. 모든 질문은 한국어로 작성해 주세요.\n",
        "\n",
        "        논문 PDF 텍스트:\n",
        "        {pdf_text}\n",
        "\n",
        "        발표 텍스트:\n",
        "        {presentation_text}\n",
        "\n",
        "        예상 질문:\n",
        "        \"\"\"\n",
        "    else:\n",
        "        return \"적절한 작업을 선택하지 않았습니다. '피드백' 또는 '질문'을 포함하는 작업을 입력하세요.\"\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=1000,\n",
        "        temperature=0.7,\n",
        "        n=1,\n",
        "        stop=None\n",
        "    )\n",
        "    return response.choices[0].text\n",
        "\n",
        "state = {\"audio_path\": None, \"pdf_path\": None, \"pdf_text\": None, \"presentation_text\": None, \"task\": None, \"saved_files\": []}\n",
        "\n",
        "def upload_files(audio, pdf):\n",
        "    try:\n",
        "        state[\"audio_path\"] = audio\n",
        "        state[\"pdf_path\"] = pdf\n",
        "        state[\"pdf_text\"] = extract_text_from_pdf(pdf)\n",
        "        state[\"presentation_text\"] = transcribe_audio(audio)\n",
        "        return \"파일 업로드가 완료되었습니다. 피드백을 원하시면 '피드백', 예상 질문을 원하시면 '질문'이라고 입력하세요.\"\n",
        "    except Exception as e:\n",
        "        return f\"파일 업로드 중 오류가 발생했습니다: {e}\"\n",
        "\n",
        "def set_task(task):\n",
        "    state[\"task\"] = task\n",
        "    return handle_task(task)\n",
        "\n",
        "def handle_task(task):\n",
        "    if state[\"audio_path\"] and state[\"pdf_path\"] and state[\"pdf_text\"] and state[\"presentation_text\"]:\n",
        "        result = generate_feedback_or_questions(state[\"pdf_text\"], state[\"presentation_text\"], task)\n",
        "        return result\n",
        "    else:\n",
        "        return \"먼저 오디오 파일과 PDF 파일을 업로드해 주세요.\"\n",
        "\n",
        "# Module 2: 논문 검색\n",
        "def download_papers_between_years(query, start_year, end_year, num_papers=10):\n",
        "    dirpath = \"./arxiv_papers\"\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)\n",
        "    \n",
        "    search_query = f\"{query} AND submittedDate:[{start_year}-01-01 TO {end_year}-12-31]\"\n",
        "    \n",
        "    client = arxiv.Client()\n",
        "    search = arxiv.Search(\n",
        "        query=search_query,\n",
        "        max_results=num_papers,\n",
        "        sort_order=arxiv.SortOrder.Descending\n",
        "    )\n",
        "    \n",
        "    saved_files = []\n",
        "    \n",
        "    for result in client.results(search):\n",
        "        while True:\n",
        "            try:\n",
        "                title = result.title.replace(' ', '_')\n",
        "                filename = f\"{result.get_short_id()}.{title}.pdf\"\n",
        "                result.download_pdf(dirpath=dirpath, filename=filename)\n",
        "                saved_files.append(filename)\n",
        "                print(f\"-> Paper id {result.get_short_id()} with title '{result.title}' is downloaded as {filename}.\")\n",
        "                break\n",
        "            except (FileNotFoundError, ConnectionResetError) as e:\n",
        "                print(\"Error occurred:\", e)\n",
        "                time.sleep(5)\n",
        "    \n",
        "    state[\"saved_files\"] = saved_files\n",
        "    return saved_files\n",
        "\n",
        "def open_pdf(file_name):\n",
        "    dirpath = \"./arxiv_papers\"\n",
        "    file_path = os.path.join(dirpath, file_name)\n",
        "    os.system(f'start {file_path}')\n",
        "\n",
        "def query_rag_model(file_name, question):\n",
        "    dirpath = \"./arxiv_papers\"\n",
        "    file_path = os.path.join(dirpath, file_name)\n",
        "\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=docs, \n",
        "        embedding=OpenAIEmbeddings()\n",
        "    )\n",
        "\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0.7)\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
        "        | rag_prompt \n",
        "        | llm \n",
        "    )\n",
        "\n",
        "    response = rag_chain.invoke(question)\n",
        "    return response.content\n",
        "\n",
        "def download_interface(query, start_year, end_year, num_papers):\n",
        "    saved_files = download_papers_between_years(query, start_year, end_year, num_papers)\n",
        "    return gr.update(choices=saved_files), \"논문이 다운로드 되었습니다.\"\n",
        "\n",
        "def open_pdf_and_chat_interface(selected_file, question):\n",
        "    if selected_file and not question:\n",
        "        open_pdf(selected_file)\n",
        "        return f\"{selected_file} 파일을 열고 있습니다...\", \"\"\n",
        "    elif selected_file and question:\n",
        "        response = query_rag_model(selected_file, question)\n",
        "        result = ''.join(filter(None, response))\n",
        "        return \"\", result\n",
        "    else:\n",
        "        return \"파일을 선택하고 질문을 입력하세요.\", \"\"\n",
        "\n",
        "def reset_interface():\n",
        "    state[\"saved_files\"] = []\n",
        "    return gr.update(visible=False), gr.update(visible=False), \"\", \"안녕하세요, 연구자를 위한 챗봇 리서처입니다. 발표 검사와 논문 검색 중 어느 모듈을 사용하실래요?\", gr.update(choices=[])\n",
        "\n",
        "# Combined Interface\n",
        "with gr.Blocks() as iface:\n",
        "    with gr.Row():\n",
        "        gr.Markdown(\"## 연구자를 위한 챗봇 리서처\")\n",
        "\n",
        "    with gr.Row():\n",
        "        chatbox = gr.Textbox(label=\"챗봇\", placeholder=\"발표 검사 또는 논문 검색을 입력하세요\")\n",
        "        chat_button = gr.Button(\"전송\")\n",
        "    \n",
        "    output_text = gr.Textbox(label=\"출력\")\n",
        "\n",
        "    with gr.Row(visible=False) as module_1:\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 발표 피드백 및 질문 생성기\")\n",
        "            audio_input = gr.Audio(type=\"filepath\", label=\"발표 녹음\")\n",
        "            pdf_input = gr.File(label=\"PDF 파일 업로드\")\n",
        "            upload_button = gr.Button(\"파일 업로드\")\n",
        "            upload_button.click(upload_files, inputs=[audio_input, pdf_input], outputs=output_text)\n",
        "            task_input = gr.Textbox(label=\"작업 입력\", placeholder=\"피드백 또는 질문\")\n",
        "            task_button = gr.Button(\"작업 전송\")\n",
        "            task_button.click(set_task, inputs=task_input, outputs=output_text)\n",
        "\n",
        "    with gr.Row(visible=False) as module_2:\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 논문 검색 및 챗봇\")\n",
        "            query_input = gr.Textbox(label=\"검색 쿼리 입력\")\n",
        "            start_year_input = gr.Number(label=\"시작 연도\")\n",
        "            end_year_input = gr.Number(label=\"종료 연도\")\n",
        "            num_papers_input = gr.Number(label=\"논문 수\")\n",
        "            download_button = gr.Button(\"논문 다운로드\")\n",
        "            saved_files_dropdown = gr.Dropdown(label=\"저장된 논문 선택\", choices=[])\n",
        "            download_button.click(download_interface, inputs=[query_input, start_year_input, end_year_input, num_papers_input], outputs=[saved_files_dropdown, output_text])\n",
        "\n",
        "            question_input = gr.Textbox(label=\"질문 입력\", placeholder=\"예: vqa의 방법론을 알려줘\")\n",
        "            query_button = gr.Button(\"질문 전송\")\n",
        "            query_button.click(open_pdf_and_chat_interface, inputs=[saved_files_dropdown, question_input], outputs=[output_text, output_text])\n",
        "\n",
        "    reset_button = gr.Button(\"초기화\")\n",
        "\n",
        "    def chatbot_response(input_text):\n",
        "        if \"발표 검사\" in input_text:\n",
        "            return \"발표 검사 모듈을 선택하셨습니다. 파일을 업로드하고 작업을 입력하세요.\", gr.update(visible=True), gr.update(visible=False)\n",
        "        elif \"논문 검색\" in input_text:\n",
        "            return \"논문 검색 모듈을 선택하셨습니다. 검색 쿼리와 조건을 입력하세요.\", gr.update(visible=False), gr.update(visible=True)\n",
        "        else:\n",
        "            return \"유효한 명령을 입력하세요: 발표 검사 또는 논문 검색.\", gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    chat_button.click(chatbot_response, inputs=chatbox, outputs=[output_text, module_1, module_2])\n",
        "    reset_button.click(reset_interface, inputs=[], outputs=[module_1, module_2, chatbox, output_text, saved_files_dropdown])\n",
        "\n",
        "iface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
